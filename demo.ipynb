{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/podmabsterio/dla_avss.git\n",
    "%cd dla_avss\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ConvTasNet** – baseline audio separation model.\n",
    "- **RTFSNet** – our main speech separation network.\n",
    "- **Video Encoder** – generates mouth embeddings used as input to RTFSNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights...\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18TEetAQ1212HoMBdnDWMd-1soRHJghA_\n",
      "From (redirected): https://drive.google.com/uc?id=18TEetAQ1212HoMBdnDWMd-1soRHJghA_&confirm=t&uuid=3597e0e3-4d7e-4ad1-9d0d-e7677c60d531\n",
      "To: /home/mabondarenko_4/dla_avss/weights/convtasnet.pth\n",
      "100%|██████████████████████████████████████| 60.7M/60.7M [00:03<00:00, 18.2MB/s]\n",
      "Download completed: weights/convtasnet.pth\n",
      "Downloading weights...\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=15tHE1Obdn7GZZ6xGy2q9s11dOqq2DGrz\n",
      "To: /home/mabondarenko_4/dla_avss/weights/rtfsnet.pth\n",
      "100%|██████████████████████████████████████| 11.0M/11.0M [00:00<00:00, 63.8MB/s]\n",
      "Download completed: weights/rtfsnet.pth\n",
      "Downloading weights...\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1TGFG0dW5M3rBErgU8i0N7M1ys9YMIvgm\n",
      "From (redirected): https://drive.google.com/uc?id=1TGFG0dW5M3rBErgU8i0N7M1ys9YMIvgm&confirm=t&uuid=e62b8e73-39e6-4089-81e4-13bfc451cc95\n",
      "To: /home/mabondarenko_4/dla_avss/weights/lrw_resnet18_dctcn_video_boundary.pth\n",
      "100%|████████████████████████████████████████| 211M/211M [00:17<00:00, 12.0MB/s]\n",
      "Download completed: weights/lrw_resnet18_dctcn_video_boundary.pth\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"weights\" # you can change dir if you want\n",
    "!bash scripts/download_convtasnet.sh $out_dir\n",
    "!bash scripts/download_rtfsnet.sh $out_dir\n",
    "!bash scripts/download_video_encoder.sh $out_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Running Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your dataset already contains ground truth signals, you can run inference and automatically compute all metrics by specifying a metric configuration in `metrics`.  \n",
    "Make sure that the dataset parameter `expect_target` is set to `True`.\n",
    "\n",
    "If your dataset is not split into train/val/test partitions, set `partition=None` during inference.\n",
    "\n",
    "Results will be saved in `predictions` directory. Before running inference, the script below removes the previous `predictions` directory (if it exists) to avoid mixing old results with new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating video embeddings:   0%|                       | 0/20 [00:00<?, ?it/s]Creating video embeddings directory: example_data/video_embeddings\n",
      "Generating video embeddings: 100%|██████████████| 20/20 [00:05<00:00,  3.61it/s]\n",
      "Video embeddings created and saved to: example_data/video_embeddings\n",
      "Creating index...\n",
      "Indexing files: 100%|██████████████████████████| 10/10 [00:00<00:00, 109.32it/s]\n",
      "RTFSNet2SpeakersSeparation(\n",
      "  (rtfs_net): RTFSNet(\n",
      "    (encoder): AudioEncoder(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(2, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (audio_bottleneck): Sequential(\n",
      "      (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (rtfs_block): RTFSBlock(\n",
      "      (scaling_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (downsampling): CompressionModule(\n",
      "        (downsampling_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gln): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "        (prelu): PReLU(num_parameters=1)\n",
      "        (compression_convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dual_path1): DualPathBlock(\n",
      "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (rnn): LSTM(512, 32, num_layers=4, bidirectional=True)\n",
      "        (conv_transpose): ConvTranspose1d(64, 64, kernel_size=(8,), stride=(1,))\n",
      "      )\n",
      "      (dual_path2): DualPathBlock(\n",
      "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (rnn): LSTM(512, 32, num_layers=4, bidirectional=True)\n",
      "        (conv_transpose): ConvTranspose1d(64, 64, kernel_size=(8,), stride=(1,))\n",
      "      )\n",
      "      (attn): TFDomainSelfAttention(\n",
      "        (qs): ModuleList(\n",
      "          (0-3): 4 x TFMHSAProjection(\n",
      "            (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (prelu): PReLU(num_parameters=1)\n",
      "            (normalization): ChannelsFeatsNormalization(\n",
      "              (ln): LayerNorm((4, 64), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ks): ModuleList(\n",
      "          (0-3): 4 x TFMHSAProjection(\n",
      "            (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (prelu): PReLU(num_parameters=1)\n",
      "            (normalization): ChannelsFeatsNormalization(\n",
      "              (ln): LayerNorm((4, 64), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (vs): ModuleList(\n",
      "          (0-3): 4 x TFMHSAProjection(\n",
      "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (prelu): PReLU(num_parameters=1)\n",
      "            (normalization): ChannelsFeatsNormalization(\n",
      "              (ln): LayerNorm((16, 64), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (out_proj): TFMHSAProjection(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (prelu): PReLU(num_parameters=1)\n",
      "          (normalization): ChannelsFeatsNormalization(\n",
      "            (ln): LayerNorm((64, 64), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsampling): ReconstructionModule(\n",
      "        (tf_ar_fusion_layers): ModuleList(\n",
      "          (0-1): 2 x TemporalFrequencyAttentionRecognition(\n",
      "            (w1): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (tf_ar_residual_layers): ModuleList(\n",
      "          (0): TemporalFrequencyAttentionRecognition(\n",
      "            (w1): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsampling_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (vp): VPBlock(\n",
      "      (scaling_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), groups=512)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (downsampling): CompressionModule1D(\n",
      "        (downsampling_conv): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
      "        (gln): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "        (prelu): PReLU(num_parameters=1)\n",
      "        (compression_convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "          (1-3): 3 x Sequential(\n",
      "            (0): Conv1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,), groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (attn): GlobalAttention(\n",
      "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (pos_enc): SinusoidalPositionalEncoding()\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (droppath): DropPath(drop_prob=0.100)\n",
      "        (ffn): Sequential(\n",
      "          (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "          (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
      "          (3): ReLU()\n",
      "          (4): DropPath(drop_prob=0.100)\n",
      "          (5): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          (6): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (7): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "      )\n",
      "      (upsampling): ReconstructionModule1D(\n",
      "        (tf_ar_fusion_layers): ModuleList(\n",
      "          (0-3): 4 x TemporalFrequencyAttentionRecognition1D(\n",
      "            (w1): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (tf_ar_residual_layers): ModuleList(\n",
      "          (0-2): 3 x TemporalFrequencyAttentionRecognition1D(\n",
      "            (w1): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsampling_conv): Conv1d(64, 512, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (caf): CAFBlock(\n",
      "      (gate_conv): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (value_conv): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (attention_conv): Sequential(\n",
      "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), groups=256)\n",
      "        (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (resize_conv): Sequential(\n",
      "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), groups=256)\n",
      "        (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (s3): S3Block(\n",
      "      (trunk): Sequential(\n",
      "        (0): PReLU(num_parameters=1)\n",
      "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (decoder): Decoder(\n",
      "      (decoder): ConvTranspose2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "All parameters: 879604\n",
      "Trainable parameters: 879604\n",
      "Loading model weights from: weights/rtfsnet.pth ...\n",
      "inf: 100%|████████████████████████████████████████| 3/3 [00:42<00:00, 14.17s/it]\n",
      "    inf_si_snri: 12.45821762084961\n",
      "    inf_si_sdri: 12.457427978515625\n",
      "    inf_si_snr: 12.542800903320312\n",
      "    inf_pesq: 2.2816102504730225\n",
      "    inf_stoi: 0.9195945262908936\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "if os.path.exists(\"predictions\"):\n",
    "    shutil.rmtree(\"predictions\")\n",
    "\n",
    "!python inference.py \\\n",
    "    -cn=inf_rtfsnet.yaml \\\n",
    "    metrics=pit \\\n",
    "    datasets.inf.partition=train \\\n",
    "    datasets.inf.expect_target=True \\\n",
    "    datasets.inf.dataset_path=example_data \\\n",
    "    video_encoder.dataset_path=example_data \\\n",
    "    inferencer.save_path=predictions \\\n",
    "    inferencer.from_pretrained=weights/rtfsnet.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your dataset contains only mixed audio (without ground-truth sources), you cannot compute separation metrics during inference.  \n",
    "In this case, use the `empty` metric configuration (an empty list of metrics) and set `expect_target=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video embeddings directory exists, skipping embeddings creation\n",
      "Creating index...\n",
      "Indexing files: 100%|█████████████████████████| 10/10 [00:00<00:00, 1177.58it/s]\n",
      "RTFSNet2SpeakersSeparation(\n",
      "  (rtfs_net): RTFSNet(\n",
      "    (encoder): AudioEncoder(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(2, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (audio_bottleneck): Sequential(\n",
      "      (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (rtfs_block): RTFSBlock(\n",
      "      (scaling_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (downsampling): CompressionModule(\n",
      "        (downsampling_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gln): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "        (prelu): PReLU(num_parameters=1)\n",
      "        (compression_convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dual_path1): DualPathBlock(\n",
      "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (rnn): LSTM(512, 32, num_layers=4, bidirectional=True)\n",
      "        (conv_transpose): ConvTranspose1d(64, 64, kernel_size=(8,), stride=(1,))\n",
      "      )\n",
      "      (dual_path2): DualPathBlock(\n",
      "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (rnn): LSTM(512, 32, num_layers=4, bidirectional=True)\n",
      "        (conv_transpose): ConvTranspose1d(64, 64, kernel_size=(8,), stride=(1,))\n",
      "      )\n",
      "      (attn): TFDomainSelfAttention(\n",
      "        (qs): ModuleList(\n",
      "          (0-3): 4 x TFMHSAProjection(\n",
      "            (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (prelu): PReLU(num_parameters=1)\n",
      "            (normalization): ChannelsFeatsNormalization(\n",
      "              (ln): LayerNorm((4, 64), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ks): ModuleList(\n",
      "          (0-3): 4 x TFMHSAProjection(\n",
      "            (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (prelu): PReLU(num_parameters=1)\n",
      "            (normalization): ChannelsFeatsNormalization(\n",
      "              (ln): LayerNorm((4, 64), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (vs): ModuleList(\n",
      "          (0-3): 4 x TFMHSAProjection(\n",
      "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (prelu): PReLU(num_parameters=1)\n",
      "            (normalization): ChannelsFeatsNormalization(\n",
      "              (ln): LayerNorm((16, 64), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (out_proj): TFMHSAProjection(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (prelu): PReLU(num_parameters=1)\n",
      "          (normalization): ChannelsFeatsNormalization(\n",
      "            (ln): LayerNorm((64, 64), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsampling): ReconstructionModule(\n",
      "        (tf_ar_fusion_layers): ModuleList(\n",
      "          (0-1): 2 x TemporalFrequencyAttentionRecognition(\n",
      "            (w1): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (tf_ar_residual_layers): ModuleList(\n",
      "          (0): TemporalFrequencyAttentionRecognition(\n",
      "            (w1): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsampling_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (vp): VPBlock(\n",
      "      (scaling_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), groups=512)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (downsampling): CompressionModule1D(\n",
      "        (downsampling_conv): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
      "        (gln): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "        (prelu): PReLU(num_parameters=1)\n",
      "        (compression_convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "          (1-3): 3 x Sequential(\n",
      "            (0): Conv1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,), groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (attn): GlobalAttention(\n",
      "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (pos_enc): SinusoidalPositionalEncoding()\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (droppath): DropPath(drop_prob=0.100)\n",
      "        (ffn): Sequential(\n",
      "          (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "          (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
      "          (3): ReLU()\n",
      "          (4): DropPath(drop_prob=0.100)\n",
      "          (5): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          (6): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (7): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "      )\n",
      "      (upsampling): ReconstructionModule1D(\n",
      "        (tf_ar_fusion_layers): ModuleList(\n",
      "          (0-3): 4 x TemporalFrequencyAttentionRecognition1D(\n",
      "            (w1): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (tf_ar_residual_layers): ModuleList(\n",
      "          (0-2): 3 x TemporalFrequencyAttentionRecognition1D(\n",
      "            (w1): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsampling_conv): Conv1d(64, 512, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (caf): CAFBlock(\n",
      "      (gate_conv): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (value_conv): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (attention_conv): Sequential(\n",
      "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), groups=256)\n",
      "        (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (resize_conv): Sequential(\n",
      "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), groups=256)\n",
      "        (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (s3): S3Block(\n",
      "      (trunk): Sequential(\n",
      "        (0): PReLU(num_parameters=1)\n",
      "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (decoder): Decoder(\n",
      "      (decoder): ConvTranspose2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "All parameters: 879604\n",
      "Trainable parameters: 879604\n",
      "Loading model weights from: weights/rtfsnet.pth ...\n",
      "inf: 100%|████████████████████████████████████████| 3/3 [00:29<00:00,  9.70s/it]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"predictions\"):\n",
    "    shutil.rmtree(\"predictions\")\n",
    "\n",
    "!python inference.py \\\n",
    "    -cn=inf_rtfsnet.yaml \\\n",
    "    metrics=empty \\\n",
    "    datasets.inf.partition=inf \\\n",
    "    datasets.inf.expect_target=False \\\n",
    "    datasets.inf.dataset_path=example_data \\\n",
    "    video_encoder.dataset_path=example_data \\\n",
    "    inferencer.save_path=predictions \\\n",
    "    inferencer.from_pretrained=weights/rtfsnet.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already saved model predictions to disk and later obtained the corresponding ground-truth sources, you can compute the separation metrics afterwards using the `calc_metrics.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "si_snri: 12.064942359924316\n",
      "si_sdri: 12.064152717590332\n",
      "si_snr: 12.145024299621582\n",
      "pesq: 2.3135225772857666\n",
      "stoi: 0.915973961353302\n"
     ]
    }
   ],
   "source": [
    "!python calc_metrics.py \\\n",
    "    -cn=calc_metrics_rtfsnet.yaml \\\n",
    "    metric_calculator.pred_path=predictions/inf \\\n",
    "    metric_calculator.gt_path=example_data/audio/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a custom dataset\n",
    "\n",
    "You can try the model with your **own dataset stored on Google Drive**.  \n",
    "Paste a public link to your dataset folder (shared via “Anyone with the link”) and it will be downloaded automatically and prepared for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yadisk\n",
    "import zipfile\n",
    "\n",
    "!mkdir -p data/datasets/\n",
    "\n",
    "dataset_link = input(\"Введите ссылку на ваш датасет (Yandex Drive / public link): \")\n",
    "y = yadisk.YaDisk()\n",
    "y.download_public(dataset_link, \"custom_dataset.zip\")\n",
    "with zipfile.ZipFile(\"custom_dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'data/datasets/with_no_gt' # change to your dataset folder name\n",
    "if os.path.isdir(os.path.join(dataset_dir, \"audio\", \"s1\")):\n",
    "    expect_target=True\n",
    "    metrics_conf=\"pit\"\n",
    "else:\n",
    "    expect_target=False\n",
    "    metrics_conf=\"empty\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating video embeddings:   0%|                       | 0/20 [00:00<?, ?it/s]Creating video embeddings directory: data/datasets/with_no_gt/video_embeddings\n",
      "Generating video embeddings: 100%|██████████████| 20/20 [00:02<00:00,  9.70it/s]\n",
      "Video embeddings created and saved to: data/datasets/with_no_gt/video_embeddings\n",
      "Creating index...\n",
      "Indexing files: 100%|█████████████████████████| 10/10 [00:00<00:00, 1294.90it/s]\n",
      "RTFSNet2SpeakersSeparation(\n",
      "  (rtfs_net): RTFSNet(\n",
      "    (encoder): AudioEncoder(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(2, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (audio_bottleneck): Sequential(\n",
      "      (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (rtfs_block): RTFSBlock(\n",
      "      (scaling_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (downsampling): CompressionModule(\n",
      "        (downsampling_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gln): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "        (prelu): PReLU(num_parameters=1)\n",
      "        (compression_convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dual_path1): DualPathBlock(\n",
      "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (rnn): LSTM(512, 32, num_layers=4, bidirectional=True)\n",
      "        (conv_transpose): ConvTranspose1d(64, 64, kernel_size=(8,), stride=(1,))\n",
      "      )\n",
      "      (dual_path2): DualPathBlock(\n",
      "        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (rnn): LSTM(512, 32, num_layers=4, bidirectional=True)\n",
      "        (conv_transpose): ConvTranspose1d(64, 64, kernel_size=(8,), stride=(1,))\n",
      "      )\n",
      "      (attn): TFDomainSelfAttention(\n",
      "        (qs): ModuleList(\n",
      "          (0-3): 4 x TFMHSAProjection(\n",
      "            (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (prelu): PReLU(num_parameters=1)\n",
      "            (normalization): ChannelsFeatsNormalization(\n",
      "              (ln): LayerNorm((4, 64), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ks): ModuleList(\n",
      "          (0-3): 4 x TFMHSAProjection(\n",
      "            (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (prelu): PReLU(num_parameters=1)\n",
      "            (normalization): ChannelsFeatsNormalization(\n",
      "              (ln): LayerNorm((4, 64), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (vs): ModuleList(\n",
      "          (0-3): 4 x TFMHSAProjection(\n",
      "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (prelu): PReLU(num_parameters=1)\n",
      "            (normalization): ChannelsFeatsNormalization(\n",
      "              (ln): LayerNorm((16, 64), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (out_proj): TFMHSAProjection(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (prelu): PReLU(num_parameters=1)\n",
      "          (normalization): ChannelsFeatsNormalization(\n",
      "            (ln): LayerNorm((64, 64), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsampling): ReconstructionModule(\n",
      "        (tf_ar_fusion_layers): ModuleList(\n",
      "          (0-1): 2 x TemporalFrequencyAttentionRecognition(\n",
      "            (w1): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (tf_ar_residual_layers): ModuleList(\n",
      "          (0): TemporalFrequencyAttentionRecognition(\n",
      "            (w1): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsampling_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (vp): VPBlock(\n",
      "      (scaling_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), groups=512)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (downsampling): CompressionModule1D(\n",
      "        (downsampling_conv): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
      "        (gln): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "        (prelu): PReLU(num_parameters=1)\n",
      "        (compression_convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "          (1-3): 3 x Sequential(\n",
      "            (0): Conv1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,), groups=64)\n",
      "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (attn): GlobalAttention(\n",
      "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (pos_enc): SinusoidalPositionalEncoding()\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (droppath): DropPath(drop_prob=0.100)\n",
      "        (ffn): Sequential(\n",
      "          (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "          (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
      "          (3): ReLU()\n",
      "          (4): DropPath(drop_prob=0.100)\n",
      "          (5): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          (6): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (7): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "      )\n",
      "      (upsampling): ReconstructionModule1D(\n",
      "        (tf_ar_fusion_layers): ModuleList(\n",
      "          (0-3): 4 x TemporalFrequencyAttentionRecognition1D(\n",
      "            (w1): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (tf_ar_residual_layers): ModuleList(\n",
      "          (0-2): 3 x TemporalFrequencyAttentionRecognition1D(\n",
      "            (w1): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w1_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w2): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w2_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (w3): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (w3_norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsampling_conv): Conv1d(64, 512, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (caf): CAFBlock(\n",
      "      (gate_conv): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (value_conv): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (attention_conv): Sequential(\n",
      "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), groups=256)\n",
      "        (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (resize_conv): Sequential(\n",
      "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), groups=256)\n",
      "        (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (s3): S3Block(\n",
      "      (trunk): Sequential(\n",
      "        (0): PReLU(num_parameters=1)\n",
      "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (decoder): Decoder(\n",
      "      (decoder): ConvTranspose2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "All parameters: 879604\n",
      "Trainable parameters: 879604\n",
      "Loading model weights from: weights/rtfsnet.pth ...\n",
      "inf: 100%|████████████████████████████████████████| 3/3 [00:26<00:00,  8.92s/it]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"predictions\"):\n",
    "    shutil.rmtree(\"predictions\")\n",
    "\n",
    "!python inference.py \\\n",
    "    -cn=inf_rtfsnet.yaml \\\n",
    "    metrics=$metrics_conf \\\n",
    "    datasets.inf.partition=null \\\n",
    "    datasets.inf.expect_target=$expect_target \\\n",
    "    datasets.inf.dataset_path=$dataset_dir \\\n",
    "    video_encoder.dataset_path=$dataset_dir \\\n",
    "    inferencer.save_path=predictions \\\n",
    "    inferencer.from_pretrained=weights/rtfsnet.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dla_avss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
